"""
è¯­éŸ³è¯†åˆ«æ¨¡å— - é‡æ„ç‰ˆ
å®ç°ChatGPTå¼çš„è¿ç»­å¯¹è¯ä½“éªŒï¼š
- æŒç»­å½•éŸ³ï¼Œæ— éœ€åå¤å¼€å…³
- æ™ºèƒ½VADè‡ªåŠ¨æ£€æµ‹è¯­éŸ³æ®µ
- å¼‚æ­¥è¯†åˆ«é˜Ÿåˆ—ï¼Œé¿å…é˜»å¡
- é«˜å‡†ç¡®ç‡çš„åºå·/å§“å+åˆ†æ•°è¯†åˆ«
"""
import wave
import numpy as np
from faster_whisper import WhisperModel
from typing import Optional, Callable
import threading
import queue
import os
import time
import re
from scipy.io.wavfile import write as wav_write
from config import (
    WHISPER_MODEL, WHISPER_DEVICE, WHISPER_COMPUTE_TYPE,
    RECORD_DURATION, SAMPLE_RATE, CHUNK_SIZE
)

# ä¼˜å…ˆä½¿ç”¨ sounddevice
try:
    import sounddevice as sd
    SOUNDDEVICE_AVAILABLE = True
    PYAUDIO_AVAILABLE = False
except ImportError:
    SOUNDDEVICE_AVAILABLE = False
    try:
        import pyaudio
        PYAUDIO_AVAILABLE = True
    except ImportError:
        PYAUDIO_AVAILABLE = False
        print("è­¦å‘Š: æœªæ‰¾åˆ°å½•éŸ³åº“ã€‚è¯·å®‰è£…: pip install sounddevice")


class ContinuousSpeechRecognition:
    """
    æŒç»­è¯­éŸ³è¯†åˆ«ç³»ç»Ÿ
    ç‰¹ç‚¹ï¼š
    1. ä¸€æ¬¡å¯åŠ¨ï¼ŒæŒç»­è¿è¡Œ
    2. æ™ºèƒ½VADè‡ªåŠ¨åˆ†æ®µ
    3. å¼‚æ­¥è¯†åˆ«ï¼Œä¸é˜»å¡å½•éŸ³
    4. é«˜å‡†ç¡®ç‡è¯†åˆ«
    """

    def __init__(self):
        self.model: Optional[WhisperModel] = None
        self._vad_warning_shown = False

        # å½•éŸ³æ§åˆ¶
        self.is_running = False  # æ•´ä¸ªç³»ç»Ÿæ˜¯å¦è¿è¡Œ
        self.recording_thread = None

        # éŸ³é¢‘ç¼“å†²
        self.audio_buffer = []
        self.buffer_lock = threading.Lock()

        # è¯†åˆ«é˜Ÿåˆ—
        self.recognition_queue = queue.Queue(maxsize=5)
        self.recognition_thread = None

        # å›è°ƒå‡½æ•°
        self.on_recognition_callback = None

        # VADçŠ¶æ€
        self.speech_started = False
        self.last_speech_time = None
        self.silence_duration = 1.5  # é™éŸ³æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        self.min_speech_duration = 0.6  # æœ€å°è¯­éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰

        # èƒ½é‡å¹³æ»‘ç¼“å†²
        self.energy_buffer = []
        self.energy_buffer_size = 5

        # å»é‡æœºåˆ¶
        self.last_recognition = ""
        self.last_recognition_time = 0

        # è®¡æ•°å™¨
        self._file_count = 0

        # åŠ è½½æ¨¡å‹
        self._load_model()

    def _load_model(self):
        """åŠ è½½Whisperæ¨¡å‹"""
        try:
            from pathlib import Path

            print("=" * 60)
            print("æ­£åœ¨åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹...")
            print(f"æ¨¡å‹: {WHISPER_MODEL}, è®¾å¤‡: {WHISPER_DEVICE}")
            print("=" * 60)

            cache_dir = Path.home() / ".cache" / "huggingface" / "hub"
            model_path = cache_dir / f"models--guillaumekln--faster-whisper-{WHISPER_MODEL}"

            if model_path.exists():
                print("âœ“ ä½¿ç”¨å·²ç¼“å­˜çš„æ¨¡å‹")
            else:
                print("âš  é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨ä¸‹è½½æ¨¡å‹ï¼ˆçº¦150MBï¼‰...")

            start_time = time.time()
            self.model = WhisperModel(
                WHISPER_MODEL,
                device=WHISPER_DEVICE,
                compute_type=WHISPER_COMPUTE_TYPE,
                download_root=None
            )

            elapsed = time.time() - start_time
            print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆï¼è€—æ—¶: {elapsed:.1f}ç§’")
            print("=" * 60)

        except Exception as e:
            print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            self.model = None

    def start(self, on_recognition: Callable[[str], None]):
        """
        å¯åŠ¨æŒç»­è¯†åˆ«ç³»ç»Ÿ
        on_recognition: è¯†åˆ«ç»“æœå›è°ƒå‡½æ•°
        """
        if self.model is None:
            print("é”™è¯¯: æ¨¡å‹æœªåŠ è½½")
            return False

        if not SOUNDDEVICE_AVAILABLE and not PYAUDIO_AVAILABLE:
            print("é”™è¯¯: æœªæ‰¾åˆ°å½•éŸ³åº“")
            return False

        if self.is_running:
            print("ç³»ç»Ÿå·²åœ¨è¿è¡Œä¸­")
            return True

        self.on_recognition_callback = on_recognition
        self.is_running = True

        # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
        self.recognition_thread = threading.Thread(
            target=self._recognition_worker,
            daemon=True
        )
        self.recognition_thread.start()

        # å¯åŠ¨å½•éŸ³çº¿ç¨‹
        self.recording_thread = threading.Thread(
            target=self._recording_worker,
            daemon=True
        )
        self.recording_thread.start()

        print("=" * 60)
        print("âœ“ æŒç»­è¯†åˆ«ç³»ç»Ÿå·²å¯åŠ¨")
        print("  è¯´è¯ä¼šè‡ªåŠ¨è¯†åˆ«ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ")
        print("  æ”¯æŒè¿ç»­è¯†åˆ«å¤šä¸ªå­¦ç”Ÿæˆç»©")
        print("=" * 60)

        return True

    def stop(self):
        """åœæ­¢æŒç»­è¯†åˆ«ç³»ç»Ÿ"""
        if not self.is_running:
            return

        print("æ­£åœ¨åœæ­¢è¯†åˆ«ç³»ç»Ÿ...")
        self.is_running = False

        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.recording_thread:
            self.recording_thread.join(timeout=2)
        if self.recognition_thread:
            self.recognition_thread.join(timeout=2)

        print("è¯†åˆ«ç³»ç»Ÿå·²åœæ­¢")

    def _recording_worker(self):
        """å½•éŸ³å·¥ä½œçº¿ç¨‹ï¼ˆæŒç»­è¿è¡Œï¼‰"""
        try:
            if SOUNDDEVICE_AVAILABLE:
                self._recording_with_sounddevice()
            else:
                self._recording_with_pyaudio()
        except Exception as e:
            print(f"å½•éŸ³çº¿ç¨‹å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()

    def _recording_with_sounddevice(self):
        """ä½¿ç”¨sounddeviceæŒç»­å½•éŸ³"""
        def audio_callback(indata, frames, time_info, status):
            if status:
                print(f"å½•éŸ³çŠ¶æ€: {status}")

            if not self.is_running:
                raise sd.CallbackStop

            # è®¡ç®—éŸ³é¢‘èƒ½é‡ï¼ˆRMSï¼‰
            audio_level = np.sqrt(np.mean(indata**2))

            # èƒ½é‡å¹³æ»‘
            self.energy_buffer.append(audio_level)
            if len(self.energy_buffer) > self.energy_buffer_size:
                self.energy_buffer.pop(0)

            smoothed_level = np.mean(self.energy_buffer)

            # VADé˜ˆå€¼ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
            threshold = 0.015  # é™ä½é˜ˆå€¼ï¼Œæ›´å®¹æ˜“è§¦å‘

            current_time = time.time()

            if smoothed_level > threshold:
                # æ£€æµ‹åˆ°è¯­éŸ³
                with self.buffer_lock:
                    self.audio_buffer.append(indata.copy())

                if not self.speech_started:
                    self.speech_started = True
                    self.last_speech_time = current_time
                    print("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³...")
                else:
                    self.last_speech_time = current_time
            else:
                # é™éŸ³
                if self.speech_started:
                    # ç»§ç»­è®°å½•é™éŸ³æ®µï¼ˆä¿æŒè¿ç»­æ€§ï¼‰
                    with self.buffer_lock:
                        self.audio_buffer.append(indata.copy())

                    # æ£€æŸ¥æ˜¯å¦é™éŸ³æ—¶é—´è¿‡é•¿
                    if (current_time - self.last_speech_time) > self.silence_duration:
                        # è¯­éŸ³æ®µç»“æŸ
                        self._process_audio_segment()
                        self.speech_started = False

        try:
            with sd.InputStream(
                samplerate=SAMPLE_RATE,
                channels=1,
                callback=audio_callback,
                blocksize=CHUNK_SIZE
            ):
                print("ğŸ™ï¸  å½•éŸ³ç³»ç»Ÿå·²å°±ç»ªï¼Œç­‰å¾…è¯­éŸ³è¾“å…¥...")
                while self.is_running:
                    time.sleep(0.1)
        except sd.CallbackStop:
            pass

    def _recording_with_pyaudio(self):
        """ä½¿ç”¨pyaudioæŒç»­å½•éŸ³ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        # ç®€åŒ–å®ç°ï¼Œä¸»è¦ä½¿ç”¨sounddevice
        print("è­¦å‘Š: pyaudioæ¨¡å¼ä¸æ”¯æŒæŒç»­è¯†åˆ«ï¼Œè¯·ä½¿ç”¨sounddevice")

    def _process_audio_segment(self):
        """å¤„ç†ä¸€ä¸ªå®Œæ•´çš„è¯­éŸ³æ®µ"""
        with self.buffer_lock:
            if len(self.audio_buffer) == 0:
                return

            # å¤åˆ¶ç¼“å†²åŒº
            audio_array = np.concatenate(self.audio_buffer, axis=0)
            self.audio_buffer = []  # æ¸…ç©ºç¼“å†²åŒº

        # æ£€æŸ¥æ—¶é•¿
        duration = len(audio_array) / SAMPLE_RATE
        if duration < self.min_speech_duration:
            print(f"  è¯­éŸ³å¤ªçŸ­ï¼ˆ{duration:.2f}ç§’ï¼‰ï¼Œå¿½ç•¥")
            return

        print(f"  è¯­éŸ³æ®µç»“æŸï¼ˆ{duration:.2f}ç§’ï¼‰ï¼ŒåŠ å…¥è¯†åˆ«é˜Ÿåˆ—...")

        # æ”¾å…¥è¯†åˆ«é˜Ÿåˆ—
        try:
            self.recognition_queue.put_nowait((audio_array, time.time()))
        except queue.Full:
            print("  è­¦å‘Š: è¯†åˆ«é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæ­¤è¯­éŸ³æ®µ")

    def _recognition_worker(self):
        """è¯†åˆ«å·¥ä½œçº¿ç¨‹ï¼ˆå¼‚æ­¥å¤„ç†ï¼‰"""
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘
                audio_array, timestamp = self.recognition_queue.get(timeout=0.5)

                # è¯†åˆ«
                text = self._recognize_audio(audio_array)

                # å»é‡æ£€æŸ¥
                if self._is_duplicate(text, timestamp):
                    print("  æ£€æµ‹åˆ°é‡å¤ï¼Œè·³è¿‡")
                    continue

                # å›è°ƒç”¨æˆ·
                if text and self.on_recognition_callback:
                    self.last_recognition = text
                    self.last_recognition_time = timestamp
                    self.on_recognition_callback(text)

            except queue.Empty:
                continue
            except Exception as e:
                print(f"è¯†åˆ«çº¿ç¨‹å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()

    def _recognize_audio(self, audio_array: np.ndarray) -> Optional[str]:
        """è¯†åˆ«éŸ³é¢‘æ•°ç»„"""
        try:
            # éŸ³é¢‘é¢„å¤„ç†
            audio_array = self._preprocess_audio(audio_array)

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            self._file_count += 1
            temp_file = f"temp_audio_{self._file_count}.wav"
            wav_write(temp_file, SAMPLE_RATE, (audio_array * 32767).astype(np.int16))

            # è°ƒç”¨Whisperè¯†åˆ«
            text = self._transcribe(temp_file)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_file)
            except:
                pass

            return text

        except Exception as e:
            print(f"  è¯†åˆ«å¤±è´¥: {e}")
            return None

    def _transcribe(self, audio_file: str) -> Optional[str]:
        """Whisperè½¬å½•ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
        if not os.path.exists(audio_file):
            return None

        try:
            print("  ğŸ” æ­£åœ¨è¯†åˆ«...")

            # ç²¾ç®€çš„promptï¼Œé¿å…æ±¡æŸ“
            # åªæä¾›æ•°å­—å’Œæ ¼å¼ä¿¡æ¯ï¼Œä¸åŒ…å«å®¹æ˜“è¯†åˆ«çš„å®Œæ•´å¥å­
            prompt = "1 2 3 4 5 6 7 8 9 10, 85 90 95 100"

            # å°è¯•ä½¿ç”¨VAD
            try:
                segments, info = self.model.transcribe(
                    audio_file,
                    beam_size=5,
                    language="zh",
                    vad_filter=True,
                    vad_parameters=dict(
                        min_silence_duration_ms=700,
                        speech_pad_ms=200,
                        threshold=0.5
                    ),
                    initial_prompt=prompt,
                    temperature=0.0,
                    condition_on_previous_text=False,
                    compression_ratio_threshold=2.4,
                    no_speech_threshold=0.5,
                    log_prob_threshold=-1.0,
                )
            except RuntimeError as e:
                if "onnxruntime" in str(e).lower():
                    if not self._vad_warning_shown:
                        print("  æç¤º: VADä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å¼")
                        self._vad_warning_shown = True
                    segments, info = self.model.transcribe(
                        audio_file,
                        beam_size=5,
                        language="zh",
                        vad_filter=False,
                        initial_prompt=prompt,
                        temperature=0.0,
                        condition_on_previous_text=False,
                        compression_ratio_threshold=2.4,
                        no_speech_threshold=0.5,
                        log_prob_threshold=-1.0,
                    )
                else:
                    raise

            # è·å–è¯†åˆ«ç»“æœ
            text = "".join(segment.text for segment in segments).strip()

            if not text:
                return None

            print(f"  åŸå§‹: {text}")

            # åå¤„ç†
            text = self._postprocess_text(text)

            print(f"  âœ“ ç»“æœ: {text}")

            return text if text else None

        except Exception as e:
            print(f"  è½¬å½•å¤±è´¥: {e}")
            return None

    def _preprocess_audio(self, audio_array: np.ndarray) -> np.ndarray:
        """éŸ³é¢‘é¢„å¤„ç†"""
        # å»é™¤DCåç§»
        audio_array = audio_array - np.mean(audio_array)

        # å½’ä¸€åŒ–
        max_val = np.max(np.abs(audio_array))
        if max_val > 0:
            audio_array = audio_array / max_val

        # é™å¹…
        audio_array = np.clip(audio_array, -1.0, 1.0)

        return audio_array

    def _postprocess_text(self, text: str) -> str:
        """æ–‡æœ¬åå¤„ç†ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if not text:
            return ""

        # 1. åŸºæœ¬æ¸…ç†
        text = text.strip()

        # 2. å»é™¤promptæ±¡æŸ“ï¼ˆå¦‚æœåŒ…å«æ˜æ˜¾çš„promptå†…å®¹ï¼‰
        # æ£€æµ‹å¹¶ç§»é™¤"æ ¼å¼"ã€"åºå·"ç­‰promptå…³é”®è¯
        pollution_keywords = ['æ ¼å¼', 'åºå·', 'ä¾‹å¦‚', 'å­¦ç”Ÿ', 'æˆç»©', 'ç™»è®°']
        for keyword in pollution_keywords:
            if keyword in text and 'å·' in text and 'åˆ†' in text:
                # å°è¯•æå–æœ‰æ•ˆéƒ¨åˆ†ï¼ˆå·å’Œåˆ†ä¹‹é—´çš„å†…å®¹ï¼‰
                # ä¾‹å¦‚ï¼š"æ ¼å¼ï¼šåºå·90åˆ†" -> "90åˆ†"ï¼ˆä½†è¿™å·²ç»æ— æ³•æ¢å¤åºå·ï¼‰
                # æ›´å¥½çš„æ–¹å¼æ˜¯ç›´æ¥è¿‡æ»¤æ‰
                parts = text.split(keyword)
                if len(parts) > 1:
                    # å–æœ€åä¸€éƒ¨åˆ†ï¼ˆæ›´å¯èƒ½æ˜¯å®é™…å†…å®¹ï¼‰
                    text = parts[-1].strip()
                    # å¦‚æœå¼€å¤´æ˜¯å†’å·æˆ–æ ‡ç‚¹ï¼Œå»é™¤
                    text = re.sub(r'^[ï¼š:ï¼Œ,ã€‚.ã€]+', '', text)

        # 3. è§„èŒƒåŒ–æ ‡ç‚¹
        text = text.replace('ï¼Œ', ',').replace('ã€‚', '.').replace('ã€', ',')

        # 4. å»é™¤è‹±æ–‡å™ªéŸ³
        text = re.sub(r'\b[A-Za-z]+\s+[A-Za-z]+\b', '', text)
        text = re.sub(r'(?<!\d)[ï¼”](?!\d)', '', text)

        # 5. ä¸­æ–‡æ•°å­—è½¬æ¢
        chinese_num_map = {
            'é›¶': '0', 'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4',
            'äº”': '5', 'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9',
            'å': '10'
        }

        for cn, num in chinese_num_map.items():
            text = re.sub(f'{cn}(?=å·)', num, text)
            text = re.sub(f'{cn}(?=åˆ†)', num, text)

        # 6. å»é‡ï¼ˆå¤„ç†è¯†åˆ«ä¸­çš„é‡å¤ï¼‰
        parts = [p.strip() for p in text.split(',')]
        unique_parts = []
        seen = set()

        for part in parts:
            if part and part not in seen:
                unique_parts.append(part)
                seen.add(part)

        text = ','.join(unique_parts)

        # 7. æ¸…ç†å¤šä½™ç¬¦å·
        text = re.sub(r',+', ',', text)
        text = re.sub(r'[,\s]+$', '', text)
        text = re.sub(r'^[,\s]+', '', text)

        return text.strip()

    def _is_duplicate(self, text: str, timestamp: float) -> bool:
        """æ£€æµ‹é‡å¤è¯†åˆ«"""
        if not text or not self.last_recognition:
            return False

        # æ—¶é—´é—´éš”å¤ªçŸ­ï¼ˆ2ç§’å†…ï¼‰
        if timestamp - self.last_recognition_time < 2.0:
            # æ–‡æœ¬ç›¸ä¼¼åº¦æ£€æŸ¥
            from difflib import SequenceMatcher
            similarity = SequenceMatcher(None, text, self.last_recognition).ratio()
            if similarity > 0.7:
                return True

        return False


# å…¼å®¹æ—§æ¥å£çš„åŒ…è£…ç±»
class SpeechRecognition:
    """
    å…¼å®¹æ—§æ¥å£çš„åŒ…è£…ç±»
    ä¿æŒå‘åå…¼å®¹ï¼ŒåŒæ—¶ä½¿ç”¨æ–°çš„æŒç»­è¯†åˆ«å¼•æ“
    """

    def __init__(self):
        self.engine = ContinuousSpeechRecognition()
        self.model = self.engine.model
        self._callback_handler = None

    def record_audio_realtime(self, on_speech_end: Callable[[str], None],
                              silence_duration: float = 1.5,
                              min_speech_duration: float = 0.6) -> bool:
        """
        å…¼å®¹æ¥å£ï¼šå®æ—¶å½•éŸ³è¯†åˆ«ä¸€æ¬¡
        å®é™…ä¸Šå¯åŠ¨æŒç»­è¯†åˆ«ï¼Œè¯†åˆ«ä¸€æ¬¡ååœæ­¢
        """
        self._callback_handler = on_speech_end

        # å¯åŠ¨æŒç»­è¯†åˆ«
        def callback_wrapper(text):
            # è¯†åˆ«ä¸€æ¬¡ååœæ­¢
            self.engine.stop()
            on_speech_end(text)

        self.engine.silence_duration = silence_duration
        self.engine.min_speech_duration = min_speech_duration

        return self.engine.start(callback_wrapper)

    def stop_recording(self):
        """åœæ­¢å½•éŸ³"""
        self.engine.stop()

    def transcribe(self, audio_file: str, use_prompt: bool = True) -> Optional[str]:
        """ç›´æ¥è½¬å½•éŸ³é¢‘æ–‡ä»¶"""
        return self.engine._transcribe(audio_file)
